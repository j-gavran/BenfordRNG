{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + '/reddit_download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../..')\n",
    "from plotting.matplotlib_setup import configure_latex, savefig, set_size_decorator, savefig, thiner_border\n",
    "\n",
    "tex_dir, images_dir = 'porocilo/main.tex', 'porocilo/images'\n",
    "\n",
    "configure_latex(style=['science', 'notebook'], global_save_path=images_dir)\n",
    "\n",
    "%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_download.RWV.pushshift.time_utils import timestamp_to_utc\n",
    "from reddit_download.RWV.pushshift.utils import build_df, apply_df_time_transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-printer",
   "metadata": {},
   "source": [
    "# Load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-franchise",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: make this faster and more efficient\n",
    "df_comments = build_df(content_type='comment', file_path=os.getcwd() + '/reddit_download')\n",
    "df_posts = build_df(content_type='post', file_path=os.getcwd() + '/reddit_download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = apply_df_time_transforms(df_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df_comments[df_comments['author'] == '[deleted]'].index\n",
    "df_comments.drop(ind, inplace=True)\n",
    "\n",
    "ind = df_comments[df_comments['author'] == 'AutoModerator'].index\n",
    "df_comments.drop(ind, inplace=True)\n",
    "\n",
    "ind = df_posts[df_posts['author'] == '[deleted]'].index\n",
    "df_posts.drop(ind, inplace=True)\n",
    "\n",
    "ind = df_posts[df_posts['author'] == 'AutoModerator'].index\n",
    "df_posts.drop(ind, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments.rename(columns={\"link_id\": \"post_id\"})\n",
    "\n",
    "df_comments = df_comments.rename(columns={\"created_utc\": \"timestamp\"})\n",
    "df_posts = df_posts.rename(columns={\"created_utc\": \"timestamp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['post_id'] = df_comments['post_id'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comments.sort_values(by='post_id', inplace=True)\n",
    "# df_posts.sort_values(by='post_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandarallel import pandarallel\n",
    "\n",
    "# pandarallel.initialize(nb_workers=12, progress_bar=True, use_memory_fs=None)\n",
    "\n",
    "# post_ids = df_posts['post_id'].unique()\n",
    "\n",
    "# def check_post_id(x, post_ids):\n",
    "#     if x in post_ids:\n",
    "#         return x\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# df_comments['post_id'] = df_comments['post_id'].parallel_apply(check_post_id, args=(post_ids, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df_comments[df_comments['post_id'] == 0].index\n",
    "df_comments.drop(ind, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-finger",
   "metadata": {},
   "source": [
    "# Link comments to posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "k, v = df_posts['post_id'], df_posts['timestamp']\n",
    "id_to_timestamp = dict(zip(k, v))\n",
    "\n",
    "import swifter\n",
    "\n",
    "def func(x, mapping):\n",
    "    try:\n",
    "        return mapping[x]\n",
    "    except KeyError:\n",
    "        return -1\n",
    "\n",
    "df_comments['post_time'] = df_comments['post_id'].swifter.apply(func, args=(id_to_timestamp, ))\n",
    "\n",
    "ind = df_comments[df_comments['post_time'] == -1].index\n",
    "df_comments.drop(ind, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.sort_values(by='score', inplace=True)\n",
    "df_posts.sort_values(by='score', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-valentine",
   "metadata": {},
   "source": [
    "# Times from post to comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benford_helper_functions import get_first_digit, benfords_test, construct_log_bins\n",
    "from random_helper_functions import get_bitstring\n",
    "from NIST_tests import RNG_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = df_comments['timestamp'].values - df_comments['post_time'].values\n",
    "times = times[times > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.hist(times, bins=50, range=[1, 60 * 10], histtype='step')\n",
    "ax.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "ax.set_xlabel('$\\Delta t$ [s]')\n",
    "ax.set_ylabel('$N$')\n",
    "# savefig('reddit_post_activity_10min', tight_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-discharge",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "plt.yscale('log')\n",
    "ax.hist(times, bins=50, range=[60 * 60 * 16, 60 * 60 * 32], histtype='step')\n",
    "ax.axvline(86400, lw=1, c='C3', ls='--')\n",
    "ax.set_xlabel('$\\Delta t$ [s]')\n",
    "ax.set_ylabel('$N$')\n",
    "# savefig('reddit_post_activity_16h_to32h', tight_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.hist(times, bins=50, range=[1, 60 * 60 * 24 * 1], histtype='step')\n",
    "ax.set_xlabel('$\\Delta t$ [s]')\n",
    "ax.set_ylabel('$N$')\n",
    "# savefig('reddit_post_activity_1day', tight_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benford_helper_functions import do_full_rng_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_truncate(arr, shape):\n",
    "    desired_size_factor = np.prod([n for n in shape if n != -1])\n",
    "    if -1 in shape:  # implicit array size\n",
    "        desired_size = arr.size // desired_size_factor * desired_size_factor\n",
    "    else:\n",
    "        desired_size = desired_size_factor\n",
    "    return arr.flat[:desired_size].reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_times = np.array_split(times, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-inclusion",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_results = []\n",
    "\n",
    "for s in split_times:\n",
    "    f = 3\n",
    "    i, j = len(s) // f, f\n",
    "\n",
    "    a = reshape_and_truncate(s, (i, j))\n",
    "    a = np.abs(a.astype(np.float64))\n",
    "    b = np.prod(a, axis=1)\n",
    "    \n",
    "    f1s, fd, fracs, chi2_tests, ks_tests, df = do_full_rng_test(b, rng_test=True, walk=False, end_bits=-1)\n",
    "    \n",
    "    split_results.append([f1s, fd, fracs, chi2_tests, ks_tests, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_matrix = []\n",
    "\n",
    "for r in split_results:\n",
    "    p_matrix.append([float(i) for i in r[-1].iloc[0].values])\n",
    "\n",
    "p_matrix = np.array(p_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stat_tests import chi2_test, ks_test\n",
    "\n",
    "fig, ax = set_size_decorator(plt.subplots, fraction=1.5, ratio='4:3')(4, 4)\n",
    "ax[-1, -1].set_visible(False)\n",
    "axs = ax.flatten()\n",
    "\n",
    "bins = 10\n",
    "for i in range(p_matrix.shape[1]):\n",
    "    m = p_matrix[:, i]\n",
    "    \n",
    "    t1 = chi2_test(m, n_bins=bins)\n",
    "    t2 = ks_test(m)\n",
    "    \n",
    "    crit = t1[1]\n",
    "    \n",
    "    axs[i].hist(m, histtype='step', lw=2, bins=bins)\n",
    "    axs[i].annotate(f'$\\chi^2={t1[0][0][0]:.2f}$', xy=(0.5, 0.1), xycoords='axes fraction', fontsize=10)\n",
    "    axs[i].set_title(f'test {i+1}')\n",
    "\n",
    "print(crit)\n",
    "# savefig('p_test_dist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = np.arange(1, 21, 1)\n",
    "\n",
    "lognorms = []\n",
    "\n",
    "for f in fs:\n",
    "    i, j = len(times) // f, f\n",
    "\n",
    "    a = reshape_and_truncate(times / f**2, (i, j))\n",
    "    a = np.abs(a.astype(np.float64))\n",
    "    b = np.prod(a, axis=1)\n",
    "    \n",
    "    lognorms.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "\n",
    "ax.hist(np.log10(lognorms[0]), bins=100, histtype='step')\n",
    "ax.hist(np.log10(lognorms[1]), bins=100, histtype='step')\n",
    "ax.hist(np.log10(lognorms[2]), bins=100, histtype='step')\n",
    "ax.hist(np.log10(lognorms[3]), bins=100, histtype='step')\n",
    "ax.hist(np.log10(lognorms[-1]), bins=100, histtype='step')\n",
    "\n",
    "ax.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "\n",
    "ax.legend(['0', '1', '2', '3', '20'])\n",
    "\n",
    "ax.set_xlabel(r'$\\log X$')\n",
    "ax.set_ylabel(r'$N$')\n",
    "\n",
    "# savefig('reddit_lognorms', tight_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-rogers",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for f in fs:\n",
    "    i, j = len(times) // f, f\n",
    "\n",
    "    a = reshape_and_truncate(times / f**2, (i, j))\n",
    "    a = np.abs(a.astype(np.float64))\n",
    "    b = np.prod(a, axis=1)\n",
    "    \n",
    "    f1s, fd, _, chi2_tests, ks_tests, df = do_full_rng_test(b, rng_test=True, end_bits=10**5, walk=False)\n",
    "    \n",
    "    results.append([f1s, fd, chi2_tests, ks_tests, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2 = []\n",
    "chi2crit = []\n",
    "ks = []\n",
    "kscrit = []\n",
    "f1 = []\n",
    "first = []\n",
    "dfs = []\n",
    "\n",
    "for r in results:\n",
    "    f1s, fd, chi2_tests, ks_tests, df = r\n",
    "    \n",
    "    chi2.append(chi2_tests[0][0][0][0])\n",
    "    chi2crit.append(chi2_tests[0][1])\n",
    "    \n",
    "    ks.append(ks_tests[0][0][0][0])\n",
    "    kscrit.append(ks_tests[0][1][0])\n",
    "    \n",
    "    f1.append(f1s[0])\n",
    "    \n",
    "    first.append(fd[0][0])\n",
    "    \n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.plot(fs, chi2, lw=1, label=r'$\\chi^2$')\n",
    "ax.scatter(fs, chi2, s=6)\n",
    "\n",
    "ax.plot(fs, chi2crit, lw=1, label=r'$\\chi^2_*$')\n",
    "ax.scatter(fs, chi2crit, s=6)\n",
    "\n",
    "ax.set_ylabel(r'$\\chi^2$')\n",
    "ax.set_xlabel(r'$\\Pi_{i=1}^N$')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# savefig('reddit_times_chi2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.plot(fs, ks, lw=1, label=r'$d$')\n",
    "ax.scatter(fs, ks, s=6)\n",
    "\n",
    "ax.plot(fs, kscrit, lw=1, label=r'$d_*$')\n",
    "ax.scatter(fs, kscrit, s=6)\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "ax.set_ylabel(r'KS')\n",
    "ax.set_xlabel(r'$\\Pi_{i=1}^N$')\n",
    "\n",
    "# savefig('reddit_times_ks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.plot(fs, abs(first - np.log10(2)), lw=1)\n",
    "ax.scatter(fs, abs(first - np.log10(2)), s=6)\n",
    "\n",
    "ax.set_ylabel(r'$|n_1 - \\log_{10}2|$')\n",
    "ax.set_xlabel(r'$\\Pi_{i=1}^N$')\n",
    "\n",
    "# savefig('reddit_times_n1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "ax.plot(fs, f1, lw=1)\n",
    "ax.scatter(fs, f1, s=6)\n",
    "\n",
    "ax.set_ylabel(r'$f_1$')\n",
    "ax.set_xlabel(r'$\\Pi_{i=1}^N$')\n",
    "\n",
    "# savefig('reddit_times_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ne dela, ker ne poznamo tocne funkcijske odvisnosti g(x)\n",
    "# from benford_helper_functions import normalize\n",
    "# from numba import njit\n",
    "\n",
    "# @njit\n",
    "# def reject(us, g, bins, h2):\n",
    "#     ys = []\n",
    "#     for i, u in enumerate(us):\n",
    "#         x = g[i]\n",
    "#         fx = h2\n",
    "        \n",
    "#         ind = np.argmin(np.abs(bins - x))\n",
    "#         gx = g[ind]\n",
    "        \n",
    "#         if u <= fx / gx:\n",
    "#             ys.append(x)\n",
    "    \n",
    "#     return ys\n",
    "\n",
    "\n",
    "# def uniform_from_any(g, us=None):\n",
    "#     \"\"\"g -> distribution used for making random numbers, u -> U(0, 1) numbers\"\"\"\n",
    "#     us = np.random.uniform(size=len(g))\n",
    "    \n",
    "#     g = g / np.max(g)\n",
    "    \n",
    "#     pdf, bins = np.histogram(g, int(np.sqrt(len(g))), density=True)\n",
    "#     bins = bins[:-1]\n",
    "    \n",
    "#     s, pairs = [], []\n",
    "#     for i in range(len(bins)):\n",
    "#         h1, b1 = pdf[i], bins[i]\n",
    "#         for j in range(len(bins)):\n",
    "#             h2, b2 = pdf[j], bins[j]\n",
    "#             S = b2 - b1 * h2\n",
    "#             s.append(S)\n",
    "#             pairs.append([h1, h2, b1, b2])\n",
    "\n",
    "#     s = np.array(s)\n",
    "#     ind = np.argsort(s)[::-1]\n",
    "#     res = pairs[ind[0]]\n",
    "\n",
    "#     h1, h2, b1, b2 = res\n",
    "    \n",
    "#     plt.plot(bins, pdf)\n",
    "#     plt.scatter([b1, b2], [h2, h2])\n",
    "    \n",
    "#     ys = reject(us, g, bins, h2)\n",
    "\n",
    "#     return ys\n",
    "\n",
    "# y = uniform_from_any(times[times < 86400])\n",
    "# plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-partner",
   "metadata": {},
   "source": [
    "# Length of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['body_len'] = df_comments['body'].apply(len)\n",
    "\n",
    "ind = df_comments[df_comments['body_len'] <= 0].index\n",
    "df_comments.drop(ind, inplace=True)\n",
    "\n",
    "df_comments.sort_values(by='score', inplace=True)\n",
    "\n",
    "body_len = df_comments['body_len'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log10(body_len), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s, first_digits, _, chi2_tests, ks_tests, df = do_full_rng_test(body_len, rng_test=True, end_bits=10**6, walk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-booking",
   "metadata": {},
   "source": [
    "# Length of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['author_len'] = df_comments['author'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_len = df_comments['author_len'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(author_len, range=(3, 20), bins=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-government",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
