{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + '/reddit_download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-plane",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../..')\n",
    "from plotting.matplotlib_setup import configure_latex, savefig, set_size_decorator, savefig, thiner_border\n",
    "\n",
    "tex_dir, images_dir = 'porocilo/main.tex', 'porocilo/images'\n",
    "\n",
    "configure_latex(style=['science', 'notebook'], global_save_path=images_dir)\n",
    "\n",
    "%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fa5ec4-6ffb-472e-839c-3eeff8c72c02",
   "metadata": {},
   "source": [
    "## preprocess and make csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reddit_download.RWV.pushshift.utils import build_df\n",
    "\n",
    "# df_comments = build_df(content_type='comment', file_path=os.getcwd() + '/reddit_download')\n",
    "# df_posts = build_df(content_type='post', file_path=os.getcwd() + '/reddit_download')\n",
    "\n",
    "# ind = df_comments[df_comments['author'] == '[deleted]'].index\n",
    "# df_comments.drop(ind, inplace=True)\n",
    "\n",
    "# ind = df_comments[df_comments['author'] == 'AutoModerator'].index\n",
    "# df_comments.drop(ind, inplace=True)\n",
    "\n",
    "# ind = df_posts[df_posts['author'] == '[deleted]'].index\n",
    "# df_posts.drop(ind, inplace=True)\n",
    "\n",
    "# ind = df_posts[df_posts['author'] == 'AutoModerator'].index\n",
    "# df_posts.drop(ind, inplace=True)\n",
    "\n",
    "# df_comments = df_comments.rename(columns={\"link_id\": \"post_id\"})\n",
    "\n",
    "# df_comments = df_comments.rename(columns={\"created_utc\": \"timestamp\"})\n",
    "# df_posts = df_posts.rename(columns={\"created_utc\": \"timestamp\"})\n",
    "\n",
    "# df_comments.to_csv('comments.csv', index=False)\n",
    "# df_posts.to_csv('posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a10a7a-dc0f-4900-8d2f-32e69471aed2",
   "metadata": {},
   "source": [
    "## modin and ray stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import swifter\n",
    "\n",
    "os.environ[\"MODIN_ENGINE\"] = \"ray\" \n",
    "os.environ[\"MODIN_CPUS\"] = \"8\"\n",
    "import ray\n",
    "ray.init(num_cpus=8)\n",
    "import modin.pandas as pd\n",
    "\n",
    "#import swifter\n",
    "\n",
    "# from distributed import Client\n",
    "# client = Client()\n",
    "\n",
    "# workers = 12\n",
    "\n",
    "# os.environ[\"MODIN_ENGINE\"] = \"ray\" \n",
    "# os.environ[\"MODIN_CPUS\"] = str(workers)\n",
    "\n",
    "# import ray\n",
    "# ray.init(num_cpus=workers)\n",
    "\n",
    "# import modin.pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from modin.config import ProgressBar\n",
    "ProgressBar.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-brother",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('comments.csv', lineterminator='\\n')\n",
    "df_posts = pd.read_csv('posts.csv', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.drop(columns=['author', 'timestamp', 'post_id', 'parent_id', 'permalink'], inplace=True)\n",
    "df_posts.drop(columns=['author', 'timestamp', 'post_id', 'num_comments', 'permalink'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments['body'] = df_comments['body'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c018f3-6336-4860-bb5e-99aa066fc691",
   "metadata": {},
   "source": [
    "## make sentences with NLTK tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reddit_download.RWV.text_processing.process_reddit import word2vec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerInput:\n",
    "    def __init__(self, text):\n",
    "        self.body = str(text)\n",
    "        self.is_post = False\n",
    "\n",
    "def body_to_sent(x):\n",
    "    return word2vec_input([TokenizerInput(x)], to_sent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_comments['sent'] = df_comments['body'].apply(body_to_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564ed1a-9c73-4df5-a2a5-06f35c270cb5",
   "metadata": {},
   "source": [
    "## sentence count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = df_comments['sent'].apply(len).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-casting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "# ax.hist(counts, bins=14, range=(1, 15), histtype='step')\n",
    "# ax.set_xlabel(r'\\# stavkov')\n",
    "# ax.set_ylabel(r'$N$')\n",
    "# savefig('sent_count', tight_layout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b479c8fc-ca6b-41c8-86c5-150b9c3f02eb",
   "metadata": {},
   "source": [
    "## char in body count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a12d50d-99fb-4494-aba0-5cc0141a693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# char_counts = df_comments['body'].apply(len).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5a849-9c0b-41ae-a4c3-39248bf91b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "# plt.hist(char_counts, range=(0, 1000), bins=100, histtype='step')\n",
    "# ax.set_xlabel(r'\\# znakov v komentarju')\n",
    "# ax.set_ylabel(r'$N$')\n",
    "# savefig('char_comment_counts', tight_layout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c59025-1714-40e0-9d18-6c78c51e3cad",
   "metadata": {},
   "source": [
    "## char in sent count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c1a47-a4e0-4afe-9a68-81ce40912797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentCharCounter:\n",
    "    def __init__(self):\n",
    "        self.counts = []\n",
    "        \n",
    "    def count(self, sent_lst):\n",
    "        for s in sent_lst:\n",
    "            self.counts.append(len(s))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f345e296-a3b2-45aa-b223-91b2f86bfabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC = SentCharCounter()\n",
    "\n",
    "# sent_char_counts = df_comments['sent'].apply(SC.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c33e9-631a-4a14-90df-f291d57f6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = sent_char_counts[0].counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b08c96-86ac-4fa5-8d96-0ec72e2108b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "# ax.hist(counts, range=(0, 500), bins=100, histtype='step')\n",
    "# ax.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "# ax.set_xlabel(r'\\# znakov v stavku')\n",
    "# ax.set_ylabel(r'$N$')\n",
    "# savefig('sent_word_count', tight_layout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b32a4-9052-471d-b050-e37b00dc93d3",
   "metadata": {},
   "source": [
    "## unique word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class WordCounter:\n",
    "    def __init__(self):\n",
    "        self.dct = dict()\n",
    "        \n",
    "    def count_words(self, s):\n",
    "        count = dict(Counter(s.split()))\n",
    "        for k, v in count.items():\n",
    "            if k not in self.dct:\n",
    "                self.dct[k] = v\n",
    "            else:\n",
    "                self.dct[k] += v\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WC = WordCounter()\n",
    "\n",
    "# res = df_comments['body'].swifter.apply(WC.count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790e5a0-3a0a-458e-8ea7-5283fefa1b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_dct = res[0].dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f8281b-38bb-4c8f-98d1-0e7062870f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_word_dct = {k: v for k, v in sorted(word_dct.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a3d0c-fa1b-40f8-b9a7-8a4d5affd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv = list(sorted_word_dct.values())[:50]\n",
    "# wk = list(sorted_word_dct.keys())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4595e01-c2fc-4ec8-bd8c-a66303a85565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = set_size_decorator(plt.subplots, fraction=0.5, ratio='4:3')(1, 1)\n",
    "\n",
    "# ax.bar(wk, wv)\n",
    "# plt.xticks(rotation=90, fontsize=5)\n",
    "# ax.minorticks_off()\n",
    "# ax.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "# savefig('word_count', tight_layout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b726a-610a-4967-94ae-356a73f0092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = df_comments._to_pandas()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d146c0-76dd-4725-b557-10ad7c1b7988",
   "metadata": {},
   "source": [
    "## bitstream for RNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b10b2-8fcf-44db-a157-9af7b558833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benford_helper_functions import str_to_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b3cdc-bb49-4d29-8b27-65d1fc9896fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1000_words = ['the', 'to', 'I', 'a', 'and', 'of', 'is', 'in', 'that', 'you', 'it', 'for', 'was', 'my', 'with', 'on', 'but', 'have', 'be', 'not', 'are', 'just', 'like', 'as', 'or', 'so', 'they', 'this', 'at', 'if', 'me', 'can', 'your', 'The', 'get', 'about', 'from', 'would', 'all', 'one', 'do', 'an', 'people', 'when', 'up', 'out', 'more', 'what', 'her', 'because', \"don't\", \"I'm\", 'we', 'had', 'he', 'i', 'some', 'think', 'will', \"it's\", 'by', 'them', 'really', 'their', 'how', 'has', 'no', 'only', 'know', 'who', 'even', 'than', 'good', 'there', 'time', 'she', 'his', 'then', 'It', 'other', 'If', 'got', 'want', 'You', 'still', 'much', 'were', 'make', 'been', 'also', 'being', 'it.', 'go', 'into', 'any', 'could', 'see', 'never', 'My', 'very', 'But', 'And', 'need', 'way', 'use', \"It's\", 'which', '-', 'most', 'first', 'going', 'him', 'after', 'something', 'where', 'This', 'too', 'I’m', 'say', 'same', 'should', 'lot', 'back', 'over', 'did', 'better', 'A', 'actually', 'now', 'every', 'So', 'pretty', 'always', 'why', 'don’t', 'someone', 'They', 'off', 'those', 'it’s', 'feel', 'since', 'That', \"I've\", 'work', 'thing', 'take', 'before', 'things', 'new', 'while', 'probably', \"you're\", 'am', 'many', 'its', 'years', 'love', 'around', 'game', 'made', 'said', \"didn't\", '2', 'sure', 'right', 'our', 'best', 'getting', \"that's\", \"can't\", 'Not', \"doesn't\", 'We', 'does', 'down', 'few', 'find', 'used', 'day', 'He', 'bad', 'What', 'enough', 'without', 'long', 'me.', 'ever', 'doing', 'look', 'thought', 'two', 'give', 'life', 'well', 'having', 'might', 'makes', 'In', 'different', 'little', 'anything', 'through', 'it,', 'these', 'already', 'try', 'both', 'When', 'put', \"I'd\", 'character', 'shit', 'mean', 'last', 'Just', 'great', 'own', 'characters', 'us', 'trying', 'until', 'another', '3', 'No', 'least', 'went', 'keep', 'There', 'point', 'person', 'old', \"isn't\", 'here', 'She', 'big', '&gt;', 'using', 'It’s', 'hard', 'that.', 'come', 'play', 'next', 'everyone', 'For', 'able', \"That's\", 'them.', 'end', 'guy', 'bit', '5', 'world', 'tell', 'kind', 'money', 'part', 'help', 'whole', 'maybe', 'everything', 'remember', 'As', 'show', 'How', 'lol', 'time.', 'high', 'once', 'year', 'damage', 'less', 'live', 'though', '4', 'seen', 'each', 'nothing', 'told', 'may', 'stuff', 'start', 'team', 'fucking', 'saying', 'friends', \"I'll\", 'started', 'gonna', 'literally', 'main', 'making', 'real', 'away', 'reason', 'far', 'guess', 'anyone', 'such', \"they're\", '1', 'looking', 'wanted', 'I’ve', 'definitely', 'watch', \"there's\", 'came', 'believe', 'between', 'gets', 'read', 'friend', 'talking', 'almost', 'man', 'you.', 'times', 'let', 'myself', 'care', 'school', 'Is', 'nice', 'else', 'understand', 'story', 'Also', 'seems', 'dont', 'found', 'done', 'saw', 'level', 'either', 'second', 'Oh', 'full', 'change', 'didn’t', 'set', 'buy', 'fuck', 'me,', 'Why', 'hate', 'place', 'instead', 'looks', 'kids', 'hope', 'called', 'anime', 'post', 'Then', 'run', 'hit', 'free', 'name', 'fun', \"wouldn't\", 'All', 'heard', 'too.', '10', 'left', 'idea', 'One', 'stop', 'Or', 'you’re', 'took', 'worth', 'usually', 'family', 'playing', 'job', 'ask', 'movie', 'during', \"wasn't\", 'call', 'single', 'quite', 'tried', 'Yeah', 'can’t', 'that’s', 'girl', 'home', 'pay', 'comes', 'top', 'kinda', 'banner', 'basically', 'Do', 'means', 'wrong', 'Thank', 'small', 'support', 'super', 'days', 'question', 'Because', 'again', 'talk', 'out.', 'Like', \"won't\", 'build', 'now.', 'water', 'up.', 'Maybe', 'Well', 'fact', 'People', 'that,', 'against', 'rather', 'thinking', 'At', 'wish', 'half', 'car', 'though.', 'problem', 'mind', 'women', 'ones', 'games', 'working', 'cause', 'under', '*', 'house', 'couple', 'especially', 'this.', 'To', 'entire', 'sex', 'side', \"Don't\", 'completely', 'food', \"he's\", 'goes', 'asked', 'likely', 'close', 'pull', 'Now', 'mom', 'I’d', 'later', 'comment', 'matter', 'watching', 'weird', 'doesn’t', 'parents', \"aren't\", 'absolutely', 'there.', 'felt', 'Even', 'u', 'video', 'hear', '&amp;', 'Your', 'happened', 'amount', 'hours', 'kid', \"she's\", 'star', 'sounds', 'wait', 'Some', 'one.', 'knew', 'eat', 'happy', 'seem', ':)', 'others', 'guys', 'well.', 'leave', 'months', 'often', 'open', 'cool', 'head', 'kill', 'yet', 'country', 'works', 'case', 'taking', 'needs', '+', 'coming', 'power', 'you,', 'says', 'based', 'im', \"haven't\", 'sense', 'become', 'whatever', 'day.', 'exactly', 'lost', 'rest', 'sometimes', 'similar', 'Zhongli', 'crit', 'due', 'night', 'must', 'lol.', 'him.', 'dps', 'time,', 'weapon', 'enjoy', 'Yeah,', 'experience', 'easy', 'Thanks', \"There's\", 'agree', 'spend', 'gave', 'human', 'body', 'her.', 'certain', 'turn', 'men', 'etc.', 'answer', 'check', 'normal', 'ago', 'unless', 'dad', 'yourself', '6', 'fine', 'life.', 'move', 'That’s', 'favorite', 'music', 'ass', 'song', 'Most', 'Good', 'huge', 'burst', 'actual', 'seeing', 'week', 'space', 'attack', 'die', 'running', 'all.', 'takes', 'black', 'watched', 'them,', 'worked', 'add', 'past', 'again.', 'woman', ',', 'Also,', 'save', 'living', \"couldn't\", 'room', 'Its', 'deal', 'outside', 'people.', 'energy', 'type', 'per', 'played', 'system', 'low', 'content', 'phone', 'number', 'current', 'true', 'face', 'possible', 'feels', 'Yes', '.', 'good.', 'episode', '20', 'gives', 'chance', 'here.', 'behind', 'straight', 'looked', 'mostly', 'I’ll', 'event', 'early', 'feeling', 'wife', 'isn’t', 'three', 'stay', 'learn', 'amazing', 'hot', 'is.', 'sound', 'shield', 'physical', 'After', \"you'll\", 'happen', 'yeah', 'course', 'front', 'way.', 'minutes', 'middle', 'asking', 'fight', 'extra', 'thank', 'important', 'original', 'shows', '?', 'imagine', 'sleep', 'stupid', 'hell', 'sort', 'Are', 'finally', 'higher', 'damn', 'series', 'needed', 'hand', 'artifacts', 'together', '100%', 'honestly', 'on.', 'given', 'wants', 'ended', 'random', \"You're\", 'worst', 'wanna', 'child', 'On', 'break', 'social', 'Yes,', 'DPS', 'Probably', 'specific', 'US', 'worse', 'Can', 'interesting', 'game.', 'thing.', 'do.', 'giving', 'scene', 'bring', 'issue', 'near', 'turned', 'rate', 'they’re', 'thanks', 'meant', 'clear', 'bunch', 'line', 'pick', 'now,', 'is,', 'multiple', 'death', 'dead', 'up,', 'order', 'years.', 'supposed', 'decided', 'girls', 'Being', 'common', 'word', 'god', 'abyss', 'With', 'version', 'future', 'it?', 'simply', 'strong', 'season', 'Well,', 'please', 'yes', 'sorry', 'longer', 'though,', '(and', 'large', 'white', \"we're\", 'Have', 'light', 'weeks', 'difference', 'age', 'Same', 'easier', 'reading', 'issues', 'fast', 'loved', 'Never', 'along', 'work.', 'account', 'Hu', '8', 'dog', 'company', 'young', 'cryo', 'No,', 'this,', 'pyro', 'piece', 'lose', 'Which', 'totally', 'cut', '(I', 'building', 'happens', 'alone', 'older', 'not.', 'electro', 'general', 'except', 'telling', '2.', 'realize', 'Venti', 'short', '/', 'easily', 'kept', 'decent', 'wasn’t', 'group', 'funny', 'hold', 'walk', '30', 'towards', 'Im', 'Did', 'Ganyu', 'better.', 'extremely', 'out,', 'currently', 'there’s', 'Eula', 'dude', 'American', 'Any', 'bought', 'consider', '&amp;#x200B;', 'glad', 'spent', 'coffee', 'Only', 'Bennett', 'knows', 'control', 'quality', 'waiting', 'late', 'soon', 'class', 'personal', 'Every', 'within', 'mine', 'met', 'several', 'allowed', 'God', 'Lol', 'moment', 'liked', 'cannot', 'inside', 'month', 'themselves', 'standard', 'crazy', 'forget', '7', 'thats', 'party', 'relationship', 'said,', '\"I', 'perfect', 'dmg', 'wouldn’t', 'across', 'health', 'drink', 'brother', 'list', 'built', 'sad', 'expect', 'example', 'recommend', 'voice', 'to.', 'book', 'self', 'stuck', 'wonder', 'taste', 'pain', 'stopped', 'choose', 'drop', 'beat', 'mean,', 'state', 'personally', 'floor', 'in.', '12', 'paid', 'sub', 'cost', 'compared', 'pity', 'Was', 'stand', 'Please', 'assume', 'died', 'depends', 'poor', '=', 'right?', 'fan', 'brain', 'whether', 'Of', 'hour', 'Diluc', 'listen', 'weapons', 'Does', 'mental', 'off.', 'explain', 'players', 'there,', 'prefer', 'lots', 'eating', 'gay', 'killed', 'children', 'mother', 'eventually', 'know,', 'hair', 'E', 'Who', '1.', \"you've\", 'questions', 'area', 'figure', 'Genshin', 'His', 'fucked', 'well,', 'bed', 'known', 'shot', 'above', 'date', 'Jean', 'too,', 'door', 'gotten', 'day,', 'much.', 'point.', 'drive', 'cant', 'Klee', 'Diona', 'things.', 'generally', 'eyes', 'artifact', 'shit.', 'government', 'fall', 'enemies', 'problems', 'following', 'opinion', 'lower', 'form', 'Those', 'boss', 'considered', 'Reddit', 'red', 'skill', 'yes,', 'Go', 'public', 'learned', 'movies', 'popular', 'pulled', 'you!', 'ok', 'OP', 'mention', 'changed', 'art', 'war', 'he’s', 'recently', 'fit', 'luck', 'college', 'hurt', 'people,', 'wear', 'lmao', 'resin', 'tho', 'miss', 'sister', 'gone', 'stars', '15', 'New', 'fully', 'average', 'walking', 'taken', 'back.', 'more.', 'one,', 'interested', ':(']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855aab03-e8af-4998-9a69-ab4760d30180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments.sort_values(by=['score'], inplace=True, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861acc4-6d6a-440c-898c-cdb196830510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text_to_bitstream(text_lst, max_bits=10**6):\n",
    "#     bit_streams = [[] for i in range(8)]\n",
    "#     for count, text in enumerate(text_lst):\n",
    "#         bits = str_to_bits(text, one_byte=False, remove_spaces=True, to_replace=top_1000_words[:256])\n",
    "#         bits_lst = bits.split(\" \")   \n",
    "        \n",
    "#         for byte in bits_lst:\n",
    "#             for i, b in enumerate(byte.zfill(8)):\n",
    "#                 bit_streams[i].append(b)\n",
    "        \n",
    "#         bit_count = len(bit_streams[0])\n",
    "        \n",
    "#         if count % 5000 == 0:\n",
    "#             print(bit_count / max_bits * 100)\n",
    "        \n",
    "#         if bit_count > max_bits:\n",
    "#             return bit_streams, count\n",
    "        \n",
    "#     return bit_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7255ee8e-54da-436b-9b88-e3565dea3335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bit_streams, count = text_to_bitstream(df_comments['body'].values, max_bits=100 * 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289eafa0-1c3b-4510-9851-95a290d64724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NIST_tests import RNG_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fe273-cbeb-4702-a96e-87fe0184715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_n_bit_streams = 1\n",
    "# max_bits = 10**6\n",
    "\n",
    "# results = []\n",
    "# for c, bit_stream in enumerate(bit_streams[2:]):\n",
    "#     print(c)\n",
    "#     bits = ''.join(bit_stream)\n",
    "    \n",
    "#     bit_pos_results = []\n",
    "#     for i in range(test_n_bit_streams):\n",
    "#         test_bits = bits[i*max_bits:max_bits]\n",
    "#         res = RNG_test(test_bits)\n",
    "#         bit_pos_results.append(res)\n",
    "        \n",
    "#     results.append(bit_pos_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a11c078-8481-49ae-81d9-a8baf7447e3b",
   "metadata": {},
   "source": [
    "## LCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e33ec-3f42-4760-a58f-082136164a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random_helper_functions import bin_str_to_matrix, split_to_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b22679-de2d-4bc2-a50f-7b0d0d93fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = ''.join(bit_streams[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68478a90-d62f-4fbd-bf84-248dbcf12a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr = r[10**6:2*10**6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3804b-d676-4fdc-8ede-3fe92497cb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG_test(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b975124f-11fe-4679-8827-909df3102717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = bin_str_to_matrix(split_to_arr(rr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14416456-ab76-455b-95b5-92951d5326e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_LCG_bits(bits, n=32, num_bits=10**6, a=48271, c=0, mod=2**32, k=0, no_chunked=True):\n",
    "    m = len(bits) // n\n",
    "\n",
    "    bits_chunked = [bits[i*m:(i+1)*m] for i in range(n)]\n",
    "    \n",
    "    new_bits = ''\n",
    "    for i in range(m):\n",
    "\n",
    "        if no_chunked:\n",
    "            b = bits[i*n:(i+1)*n]\n",
    "        else:\n",
    "            b = ''\n",
    "            for j in range(n):\n",
    "                b += bits_chunked[j][i]\n",
    "        \n",
    "        if mod != 0:\n",
    "            b = bin((int(b, 2) * a + c) % mod)[2:]\n",
    "        else:\n",
    "            b = bin(int(b, 2) * a + c)[2:]\n",
    "        \n",
    "        if k != 0:\n",
    "            new_bits += b[int(len(b) - len(b) * k):]\n",
    "        else:\n",
    "            new_bits += b[len(b)//2:]\n",
    "        \n",
    "        if len(new_bits) > num_bits:\n",
    "            return new_bits, i * n\n",
    "        \n",
    "    return new_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f905e-be82-4607-bf3a-4ff53aeb195e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bit_str = ''.join(bit_streams[7])\n",
    "# st, used = make_LCG_bits(bit_str, num_bits=10**6,\n",
    "#                          a=1664525, c=1013904223, mod=2**32 - 1, k=0, n=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2993567f-6642-4f8d-9ead-d102398180a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG_test(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f03f1b-8a81-43f4-97cf-c9b91741209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used / 10**6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf2bf2d-f5e5-4a56-94ba-ce865ba8ce8d",
   "metadata": {},
   "source": [
    "## chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b527b80f-4910-47f2-86cc-502186ff4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bit_chunk(bits, n):\n",
    "    m = len(bits) // n\n",
    "    bits_chunked = [bits[i*m:(i+1)*m] for i in range(n)]\n",
    "    return bits_chunked\n",
    "\n",
    "\n",
    "def make_bit_chunks(bits, n=32, splits=2, prnt=False):\n",
    "    end_parts, elements = n**(splits + 1), len(bits) // n**(splits + 1)\n",
    "    if prnt:\n",
    "        print(f'end parts: {end_parts} with {elements} elements')\n",
    "    bits_chunked = make_bit_chunk(bits, n)\n",
    "    \n",
    "    if splits == 0:\n",
    "        return bits_chunked, end_parts, elements\n",
    "\n",
    "    for split in range(splits):\n",
    "        split_chunks = []\n",
    "        for chunk in bits_chunked:\n",
    "            split_chunks += make_bit_chunk(chunk, n)\n",
    "        bits_chunked = split_chunks\n",
    "    \n",
    "    return bits_chunked, end_parts, elements\n",
    "\n",
    "\n",
    "def make_bitstring_from_chunks(bits, num_bits=10**6, **kwargs):\n",
    "    bits_chunked, n_chunks, elements = make_bit_chunks(bits, **kwargs)\n",
    "    \n",
    "    bitstring = ''\n",
    "    for i in range(elements):\n",
    "        for j in range(n_chunks):\n",
    "            b = bits_chunked[j][i]\n",
    "            bitstring += b\n",
    "            if len(bitstring) > num_bits:\n",
    "                return bitstring\n",
    "        \n",
    "    return bitstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ddf7db-1da9-4c54-a1ba-61a54470e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#st = np.arange(0, 12, 1).astype(str)\n",
    "st = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l']\n",
    "st = ''.join(st).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447b016-a6f7-45db-aaf7-2e4ebca5a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_mix(st, n_mixes=None, chunks=None):\n",
    "    starting_st = st\n",
    "    \n",
    "    if chunks is None:\n",
    "        n = int(np.sqrt(len(st))) - 1\n",
    "    else:\n",
    "        n = chunks\n",
    "    print(f'splits: {n}')\n",
    "    \n",
    "    if n_mixes is None:\n",
    "        n_mixes = n\n",
    "        \n",
    "    for i in tqdm(range(n_mixes)):\n",
    "        st = make_bitstring_from_chunks(st, n=n, splits=1)\n",
    "        if st == starting_st:\n",
    "            print('sequence repeated! returnig last good combination!')\n",
    "            return old_st\n",
    "        old_st = st\n",
    "    \n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c6f52-b538-4c99-9603-75cd562604c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_mix(st, chunks=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0bced-9ea8-478a-ab08-4b4565179f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# c = make_bitstring_from_chunks(bit_str, num_bits=10**6, n=32, splits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d37b7-c3a0-4fea-af19-1e0892d41ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df_comments['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3a0a3-fbfb-4b8d-ac1e-195a57488cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = ''.join(text)[:10**6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb747f-f68d-42ef-b49d-f00258cdce9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces_bits = str_to_bits(full_text, to_replace=top_1000_words[:100], remove_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a9a5e6-88d2-4a6d-9b8e-3293e1712ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bits = list(spaces_bits.split(\" \"))\n",
    "\n",
    "last_bit = ''\n",
    "for b in list_bits:\n",
    "    last_bit += b[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567f9b1-7c88-486d-a932-33a30b7ba3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG_test(last_bit[:2*10**6][::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee577a09-aeee-41cc-9528-3808c547ff74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mm = multi_mix(last_bit[:1*10**6], n_mixes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3621e77a-0edc-43d2-b90b-0ddccb5f13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNG_test(mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad5464-8712-49ec-a5c5-49d40bfe9f86",
   "metadata": {},
   "source": [
    "## diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6620ec-ab35-4e6c-b2cf-b0baf8ac6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_shapes(num):\n",
    "    shapes = []\n",
    "    lim = int(np.sqrt(num))\n",
    "    for i in range (1, lim):\n",
    "        if num % i == 0:\n",
    "            shapes.append([i, int(num/i)])\n",
    "    \n",
    "    return shapes[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866f1dfa-2ea7-4253-9a7f-3f9053a618d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def diag_rng(bit_arr, reverse_shapes=False, reverse_sort=False):\n",
    "    if reverse_shapes:\n",
    "        shapes = valid_shapes(len(bit_arr))[:-1][::-1]\n",
    "    else:\n",
    "        shapes = valid_shapes(len(bit_arr))[:-1]\n",
    "\n",
    "    for shape in tqdm(shapes):\n",
    "        new_bit_arr = bit_arr.reshape(shape[0], shape[1])\n",
    "        \n",
    "        m = max(shape)\n",
    "        r = np.arange(-m, m + 1, 1)\n",
    "        \n",
    "        new_s = []\n",
    "        for i in r:\n",
    "            s = np.diag(new_bit_arr, k=i).astype(str)\n",
    "            if len(s) != 0:\n",
    "                new_s.append(''.join(s))\n",
    "        \n",
    "        new_s.sort(key=lambda x: len(x[0]), reverse=reverse_sort)\n",
    "        new_s = list(itertools.chain.from_iterable(new_s))\n",
    "        new_s = ''.join(new_s)\n",
    "        \n",
    "        bit_arr = split_to_arr(new_s)\n",
    "    \n",
    "    return new_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b37562-a415-49a6-b684-c3ebf651f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = last_bit[:10**6]\n",
    "\n",
    "# a = diag_rng(split_to_arr(a), reverse=False)\n",
    "# a = make_bitstring_from_chunks(a, num_bits=1*10**6, n=32, splits=0)\n",
    "diag_bits = diag_rng(split_to_arr(a))\n",
    "mm = multi_mix(diag_bits, n_mixes=1, chunks=32)\n",
    "# diag_bits = diag_rng(split_to_arr(mm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb3d99-4846-4d5c-8347-5c91b7b03d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_test(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7610d0-f255-4d5b-b9b9-f1fec94e5434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = last_bit[:1*10**6]\n",
    "a = make_bitstring_from_chunks(a, num_bits=1*10**6, n=32, splits=2)\n",
    "a_arr = split_to_arr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f06e96-64d1-46c2-805c-0154146ce699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diag_bits = diag_rng(a_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9141abe1-78fb-4ad8-ac80-14a1a743e012",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_test(diag_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9af132-464e-453b-ab3e-1684c9ec749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG_test(a[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a947dc-33b8-416b-b9c0-2ffbec2f5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bitstring import BitArray\n",
    "\n",
    "# def float_from_bitstring(bitstring):\n",
    "#     return BitArray(bin=bitstring).float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef649fa5-522b-4de8-85d2-39a9ad40f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ints_with_n_bits(bits, n):\n",
    "    m = len(bits) // n\n",
    "    \n",
    "    ints = []\n",
    "    z = 0\n",
    "    for i in range(m):\n",
    "        take = bits[i*n:(i+1)*n]\n",
    "        make_int = int(take, 2)\n",
    "        if make_int != 0:\n",
    "            ints.append(make_int)\n",
    "        else:\n",
    "            z += 1\n",
    "    \n",
    "    print(f'{z} total zeros')\n",
    "    return np.array(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75601487-8840-4ed9-8ab5-a1a8a556ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_truncate(arr, shape):\n",
    "    desired_size_factor = np.prod([n for n in shape if n != -1])\n",
    "    if -1 in shape:  # implicit array size\n",
    "        desired_size = arr.size // desired_size_factor * desired_size_factor\n",
    "    else:\n",
    "        desired_size = desired_size_factor\n",
    "    return arr.flat[:desired_size].reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28209bd-4afd-4d8f-a2af-8c6e49de536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lognormal_dist(bits, n, d):\n",
    "    \"\"\"\n",
    "    bits: str\n",
    "        Sequence of bits\n",
    "    n: int\n",
    "        Number of bits to take together in bits sequence\n",
    "    d: int\n",
    "        Number of multiplications\n",
    "    \"\"\"\n",
    "    ints = make_ints_with_n_bits(last_bit, n=n)\n",
    "    ints_mat = reshape_and_truncate(bits, (len(ints) // d, d))\n",
    "    ints_prod = np.prod(ints_mat, axis=1).astype(np.float32)\n",
    "    return ints_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd05dd-a82f-4882-aea1-24152c51e57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876ecc8-4aba-4e35-a23d-2d7f58f7a69c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
